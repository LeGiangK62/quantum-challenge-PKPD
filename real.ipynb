{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a063ca4-4086-437f-81f5-b543a8cf0f39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected columns: {'ID': 'ID', 'TIME': 'TIME', 'DV': 'DV', 'EVID': 'EVID', 'AMT': 'AMT', 'BW': 'BW', 'COMED': 'COMED'}\n",
      "PD rows: 1200 Dose rows: 756\n",
      "[ID split by fixed dose groups] (70/15/15)\n",
      " train IDs: 24 | valid IDs: 6 | test IDs: 6\n",
      " 1mg -> train/valid/test: 8 2 2\n",
      " 3mg -> train/valid/test: 8 2 2\n",
      "10mg -> train/valid/test: 8 2 2\n",
      "#samples -> train: 600 | valid: 150 | test: 150\n",
      "[ep 001] acc=0.780 f1=0.492 prec=0.485 rec=0.500 roc_auc=0.705 pr_auc=0.492\n",
      "[ep 002] acc=0.787 f1=0.000 prec=0.000 rec=0.000 roc_auc=0.729 pr_auc=0.472\n",
      "[ep 003] acc=0.787 f1=0.000 prec=0.000 rec=0.000 roc_auc=0.764 pr_auc=0.436\n",
      "[ep 010] acc=0.833 f1=0.545 prec=0.652 rec=0.469 roc_auc=0.757 pr_auc=0.517\n",
      "[ep 020] acc=0.873 f1=0.698 prec=0.710 rec=0.688 roc_auc=0.865 pr_auc=0.728\n",
      "[ep 030] acc=0.913 f1=0.812 prec=0.757 rec=0.875 roc_auc=0.975 pr_auc=0.940\n",
      "[ep 040] acc=0.947 f1=0.871 prec=0.900 rec=0.844 roc_auc=0.989 pr_auc=0.968\n",
      "[ep 050] acc=0.953 f1=0.881 prec=0.963 rec=0.812 roc_auc=0.991 pr_auc=0.970\n",
      "[ep 060] acc=0.940 f1=0.847 prec=0.926 rec=0.781 roc_auc=0.987 pr_auc=0.957\n",
      "best(valid): {'epoch': 46, 'acc': 0.96, 'prec': 0.9642857142857143, 'rec': 0.84375, 'f1': 0.9, 'roc_auc': np.float64(0.9902012711864407), 'pr_auc': np.float64(0.9692827311079643), 'tn': np.int64(117), 'fp': np.int64(1), 'fn': np.int64(5), 'tp': np.int64(27)}\n",
      "\n",
      "Validation best: {'epoch': 46, 'acc': 0.96, 'prec': 0.9642857142857143, 'rec': 0.84375, 'f1': 0.9, 'roc_auc': np.float64(0.9902012711864407), 'pr_auc': np.float64(0.9692827311079643), 'tn': np.int64(117), 'fp': np.int64(1), 'fn': np.int64(5), 'tp': np.int64(27)}\n",
      "\n",
      "=== Dose recommendations summary ===\n",
      "           scenario target  once-daily (mg)  once-weekly (mg)\n",
      "Base (Phase 1-like)    90%              5.5              50.0\n",
      "       BW 70–140 kg    90%              7.5              70.0\n",
      "   No COMED allowed    90%              5.5              55.0\n",
      "Base (Phase 1-like)    75%              4.0              35.0\n",
      "\n",
      "=== Final TEST metrics (unseen IDs) ===\n",
      "     acc: 0.9000\n",
      "    prec: 0.7500\n",
      "     rec: 0.8919\n",
      "      f1: 0.8148\n",
      " roc_auc: 0.9567\n",
      "  pr_auc: 0.8627\n",
      "      tn: 102\n",
      "      fp: 11\n",
      "      fn: 4\n",
      "      tp: 33\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# PD-only 분류 + 정상상태 용량탐색 (MLP 전용, 지표 확장, CSV 저장 없음)\n",
    "# - 데이터: EstData.csv (PD 단위: ng/mL), 임계 3.3 ng/mL\n",
    "# - 모델: MLP (은닉층 개수/히든/드롭아웃 하이퍼파라미터화)\n",
    "# - 분할: 플라시보(0 mg, ID 1–12) 제외, 1/3/10 mg 고정 그룹별 80/20 ID 단위 분할\n",
    "# ===========================\n",
    "from torch.utils.data import DataLoader\n",
    "import os, math, warnings, numpy as np, pandas as pd\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix\n",
    ")\n",
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "# -------- 설정 --------\n",
    "CSV = \"EstData.csv\"       # 필요 시 \"/mnt/data/EstData.csv\"\n",
    "PD_THRESHOLD = 3.3\n",
    "EPOCHS = 60\n",
    "LR = 5e-2\n",
    "N_SUBJ = 300\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# MLP 하이퍼파라미터\n",
    "MLP_HIDDEN = 36\n",
    "MLP_LAYERS = 2\n",
    "MLP_DROPOUT = 0.2\n",
    "\n",
    "assert os.path.exists(CSV), f\"CSV not found at {CSV}\"\n",
    "\n",
    "# -------- 유틸: 열 이름 추론 --------\n",
    "def _find_col_like(df, name_opts):\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for n in name_opts:\n",
    "        if n in low: return low[n]\n",
    "    return None\n",
    "\n",
    "# -------- 데이터 로딩/전처리 --------\n",
    "df = pd.read_csv(CSV)\n",
    "\n",
    "col_ID   = _find_col_like(df, [\"id\"])\n",
    "col_TIME = _find_col_like(df, [\"time\"])\n",
    "col_DVID = _find_col_like(df, [\"dvid\"])\n",
    "col_DV   = _find_col_like(df, [\"dv\",\"pd\",\"value\"])\n",
    "col_EVID = _find_col_like(df, [\"evid\"])\n",
    "col_AMT  = _find_col_like(df, [\"amt\",\"dose\",\"dosen\",\"doses\"])\n",
    "col_BW   = _find_col_like(df, [\"bw\",\"weight\",\"bodyweight\"])\n",
    "col_COMED= _find_col_like(df, [\"comed\",\"conmed\",\"concom\"])\n",
    "\n",
    "need = [col_ID, col_TIME, col_DV, col_AMT]\n",
    "miss = [n for n,v in zip([\"ID\",\"TIME\",\"DV\",\"AMT/DOSE\"], need) if v is None]\n",
    "if miss:\n",
    "    warnings.warn(f\"Columns missing (minimum required): {miss}\")\n",
    "\n",
    "# PD 행 추출 (DVID==2가 있으면 그걸 사용)\n",
    "if col_DVID is not None and col_DV is not None:\n",
    "    pdf = df[df[col_DVID]==2].copy()\n",
    "else:\n",
    "    pdf = df.copy()\n",
    "\n",
    "# 투약 이벤트 (EVID==1 우선, 아니면 AMT/DOSE notna)\n",
    "if col_EVID is not None:\n",
    "    dose_df = df[df[col_EVID]==1].copy()\n",
    "else:\n",
    "    dose_df = df[df[col_AMT].notna()].copy()\n",
    "\n",
    "# 숫자 변환\n",
    "for c in [col_TIME, col_DV, col_AMT, col_BW, col_COMED]:\n",
    "    if c is not None:\n",
    "        pdf[c] = pd.to_numeric(pdf[c], errors=\"coerce\")\n",
    "        dose_df[c] = pd.to_numeric(dose_df[c], errors=\"coerce\")\n",
    "\n",
    "# 정렬/필요 열만\n",
    "keep_pd = [c for c in [col_ID,col_TIME,col_DV,col_BW,col_COMED] if c is not None]\n",
    "keep_dose = [c for c in [col_ID,col_TIME,col_AMT] if c is not None]\n",
    "pdf = pdf[keep_pd].dropna().sort_values([col_ID, col_TIME])\n",
    "dose_df = dose_df[keep_dose].dropna().sort_values([col_ID, col_TIME])\n",
    "\n",
    "print(\"Detected columns:\", dict(ID=col_ID, TIME=col_TIME, DV=col_DV, EVID=col_EVID, AMT=col_AMT, BW=col_BW, COMED=col_COMED))\n",
    "print(\"PD rows:\", len(pdf), \"Dose rows:\", len(dose_df))\n",
    "\n",
    "# -------- 데이터셋 --------\n",
    "class PDSamples(Dataset):\n",
    "    def __init__(self, pd_df: pd.DataFrame, dose_df: pd.DataFrame,\n",
    "                 col_ID: str, col_TIME: str, col_DV: str,\n",
    "                 col_BW: Optional[str], col_COMED: Optional[str], pd_threshold: float=3.3):\n",
    "        self.col_ID, self.col_TIME, self.col_DV = col_ID, col_TIME, col_DV\n",
    "        self.col_BW, self.col_COMED = col_BW, col_COMED\n",
    "        self.pd_threshold = pd_threshold\n",
    "\n",
    "        # ID별 투약 히스토리\n",
    "        d_groups = defaultdict(list)\n",
    "        for _, row in dose_df.iterrows():\n",
    "            d_groups[row[col_ID]].append((float(row[col_TIME]), float(row[col_AMT])))\n",
    "        self.dose_map = {k: (np.array([t for t,a in v], dtype=np.float32),\n",
    "                              np.array([a for t,a in v], dtype=np.float32)) for k,v in d_groups.items()}\n",
    "\n",
    "        # 샘플: 각 PD 관측 시점\n",
    "        feats = []\n",
    "        for _, row in pd_df.iterrows():\n",
    "            sid = row[col_ID]\n",
    "            if sid not in self.dose_map:\n",
    "                continue\n",
    "            t = float(row[col_TIME])\n",
    "            val = float(row[col_DV])\n",
    "            y = 1.0 if (val <= pd_threshold) else 0.0\n",
    "            bw = float(row[col_BW]) if col_BW is not None else 70.0\n",
    "            cm = float(row[col_COMED]) if col_COMED is not None else 0.0\n",
    "            feats.append((sid, t, y, bw, cm))\n",
    "        self.samples = feats\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sid, t, y, bw, cm = self.samples[idx]\n",
    "        dose_t, dose_a = self.dose_map.get(sid, (np.zeros(0, dtype=np.float32), np.zeros(0, dtype=np.float32)))\n",
    "        return {\n",
    "            \"t\": torch.tensor(t, dtype=torch.float32),\n",
    "            \"y\": torch.tensor(y, dtype=torch.float32),\n",
    "            \"bw\": torch.tensor(bw, dtype=torch.float32),\n",
    "            \"cm\": torch.tensor(cm, dtype=torch.float32),\n",
    "            \"dose_t\": torch.tensor(dose_t, dtype=torch.float32),\n",
    "            \"dose_a\": torch.tensor(dose_a, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "def _collate(batch): return batch\n",
    "\n",
    "dataset_all = PDSamples(pdf, dose_df, col_ID, col_TIME, col_DV, col_BW, col_COMED, pd_threshold=PD_THRESHOLD)\n",
    "\n",
    "# -------- ID 단위 분할: 플라시보 제외 + 고정 그룹(1/3/10 mg)별 80/20 --------\n",
    "rng = 42\n",
    "placebo_ids = set(range(1, 13))     # 0 mg (제외)\n",
    "ids_1mg     = list(range(13, 25))   # 1 mg\n",
    "ids_3mg     = list(range(25, 37))   # 3 mg\n",
    "ids_10mg    = list(range(37, 49))   # 10 mg\n",
    "\n",
    "ids_in_data = set(df[col_ID].unique())\n",
    "ids_1mg  = sorted(ids_in_data.intersection(ids_1mg))\n",
    "ids_3mg  = sorted(ids_in_data.intersection(ids_3mg))\n",
    "ids_10mg = sorted(ids_in_data.intersection(ids_10mg))\n",
    "\n",
    "def split_70_15_15(ids, seed=42):\n",
    "    if len(ids) == 0:\n",
    "        return [], [], []\n",
    "    # 70% train vs 30% temp\n",
    "    tr_ids, temp_ids = train_test_split(ids, test_size=0.30, random_state=seed, shuffle=True)\n",
    "    # temp을 15/15로 반분\n",
    "    va_ids, te_ids = train_test_split(temp_ids, test_size=0.50, random_state=seed, shuffle=True)\n",
    "    return list(tr_ids), list(va_ids), list(te_ids)\n",
    "\n",
    "tr_1, va_1, te_1   = split_70_15_15(ids_1mg,  seed=rng)\n",
    "tr_3, va_3, te_3   = split_70_15_15(ids_3mg,  seed=rng)\n",
    "tr_10, va_10, te_10 = split_70_15_15(ids_10mg, seed=rng)\n",
    "\n",
    "ids_tr = set(tr_1 + tr_3 + tr_10)\n",
    "ids_va = set(va_1 + va_3 + va_10)\n",
    "ids_te = set(te_1 + te_3 + te_10)\n",
    "\n",
    "sid_list = [s[0] for s in dataset_all.samples]  # (sid, t, y, bw, cm)\n",
    "tr_idx = [i for i, sid in enumerate(sid_list) if sid in ids_tr]\n",
    "va_idx = [i for i, sid in enumerate(sid_list) if sid in ids_va]\n",
    "te_idx = [i for i, sid in enumerate(sid_list) if sid in ids_te]\n",
    "\n",
    "train_ds = Subset(dataset_all, tr_idx)\n",
    "valid_ds = Subset(dataset_all, va_idx)\n",
    "test_ds  = Subset(dataset_all, te_idx)\n",
    "\n",
    "print(\"[ID split by fixed dose groups] (70/15/15)\")\n",
    "print(\" train IDs:\", len(ids_tr), \"| valid IDs:\", len(ids_va), \"| test IDs:\", len(ids_te))\n",
    "print(\" 1mg -> train/valid/test:\", len(tr_1), len(va_1), len(te_1))\n",
    "print(\" 3mg -> train/valid/test:\", len(tr_3), len(va_3), len(te_3))\n",
    "print(\"10mg -> train/valid/test:\", len(tr_10), len(va_10), len(te_10))\n",
    "print(f\"#samples -> train: {len(train_ds)} | valid: {len(valid_ds)} | test: {len(test_ds)}\")\n",
    "\n",
    "# -------- MLP 모델 --------\n",
    "class PDMLPClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    입력 x=[E(t), (BW-mean)/10, COMED] -> [Linear+ReLU(+Dropout)]*n_layers -> Linear(→1)\n",
    "    노출 계산용 링크: log(tau) = b0 + b1*((BW-mean)/10) + b2*COMED\n",
    "    \"\"\"\n",
    "    def __init__(self, bw_mean: float=70.0, hidden: int=32, n_layers: int=3, dropout_p: float=0.2):\n",
    "        super().__init__()\n",
    "        # tau 링크 파라미터\n",
    "        self.b0 = nn.Parameter(torch.tensor(math.log(24.0)))\n",
    "        self.b1 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.b2 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.bw_mean = float(bw_mean)\n",
    "\n",
    "        layers = []\n",
    "        in_dim = 3\n",
    "        for i in range(n_layers):\n",
    "            layers += [\n",
    "                nn.Linear(in_dim if i==0 else hidden, hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=dropout_p) if dropout_p and dropout_p > 0 else nn.Identity(),\n",
    "            ]\n",
    "        layers += [nn.Linear(hidden if n_layers>0 else in_dim, 1)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def _tau(self, bw: torch.Tensor, comed: torch.Tensor):\n",
    "        bwc = (bw - self.bw_mean) / 10.0\n",
    "        log_tau = self.b0 + self.b1*bwc + self.b2*comed\n",
    "        return torch.exp(log_tau).clamp_min(1.0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def tau_from_cov_np(self, bw_np: np.ndarray, cm_np: np.ndarray, device=None):\n",
    "        device = device or next(self.parameters()).device\n",
    "        bw = torch.tensor(bw_np, dtype=torch.float32, device=device)\n",
    "        cm = torch.tensor(cm_np, dtype=torch.float32, device=device)\n",
    "        return self._tau(bw, cm).detach().cpu().numpy()\n",
    "\n",
    "    def forward_single(self, t: torch.Tensor, dose_t: torch.Tensor, dose_a: torch.Tensor,\n",
    "                       bw: float, comed: float):\n",
    "        tau = self._tau(torch.tensor(bw, dtype=torch.float32, device=t.device),\n",
    "                        torch.tensor(comed, dtype=torch.float32, device=t.device))\n",
    "        dt = t - dose_t\n",
    "        mask = (dt >= 0).float()\n",
    "        exposure = (dose_a * torch.exp(-dt.clamp_min(0) / tau) * mask).sum()\n",
    "        x = torch.stack([\n",
    "            exposure,\n",
    "            (torch.tensor(bw, dtype=torch.float32, device=t.device) - self.bw_mean) / 10.0,\n",
    "            torch.tensor(comed, dtype=torch.float32, device=t.device)\n",
    "        ])\n",
    "        return self.mlp(x).squeeze()\n",
    "\n",
    "def _collate(batch): return batch\n",
    "\n",
    "# -------- 지표 계산 --------\n",
    "def _compute_metrics(y_true: np.ndarray, prob: np.ndarray, thr: float = 0.5):\n",
    "    pred = (prob >= thr).astype(int)\n",
    "    acc = accuracy_score(y_true, pred) if len(y_true) else float(\"nan\")\n",
    "    prec = precision_score(y_true, pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, pred, zero_division=0)\n",
    "    try:\n",
    "        roc = roc_auc_score(y_true, prob) if (len(np.unique(y_true))>1) else float(\"nan\")\n",
    "    except Exception:\n",
    "        roc = float(\"nan\")\n",
    "    try:\n",
    "        ap  = average_precision_score(y_true, prob) if (len(np.unique(y_true))>1) else float(\"nan\")\n",
    "    except Exception:\n",
    "        ap  = float(\"nan\")\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, pred, labels=[0,1]).ravel()\n",
    "    except Exception:\n",
    "        tn=fp=fn=tp = 0\n",
    "    return {\"acc\":acc, \"prec\":prec, \"rec\":rec, \"f1\":f1, \"roc_auc\":roc, \"pr_auc\":ap,\n",
    "            \"tn\":tn, \"fp\":fp, \"fn\":fn, \"tp\":tp}\n",
    "\n",
    "# -------- 학습 루틴 (MLP 전용) --------\n",
    "def train_classifier(train_ds, valid_ds, pd_threshold=3.3, epochs=60, lr=5e-2, seed=42,\n",
    "                     mlp_hidden=32, mlp_layers=3, mlp_dropout=0.2):\n",
    "    device = DEVICE\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    tr_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=_collate, generator=g)\n",
    "    va_loader = DataLoader(valid_ds, batch_size=256, shuffle=False, collate_fn=_collate)\n",
    "\n",
    "    bw_mean = float(np.mean([b[\"bw\"].item() for b in train_ds]))\n",
    "    model = PDMLPClassifier(bw_mean=bw_mean, hidden=mlp_hidden, n_layers=mlp_layers, dropout_p=mlp_dropout).to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "    best = (-1.0, None)\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for batch in tr_loader:\n",
    "            opt.zero_grad()\n",
    "            loss = 0.0\n",
    "            for b in batch:\n",
    "                logit = model.forward_single(b[\"t\"].to(device), b[\"dose_t\"].to(device), b[\"dose_a\"].to(device),\n",
    "                                             float(b[\"bw\"]), float(b[\"cm\"]))\n",
    "                loss = loss + loss_fn(logit.view(()), b[\"y\"].to(device).view(()))\n",
    "            (loss/len(batch)).backward()\n",
    "            opt.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval(); ys=[]; ps=[]\n",
    "        with torch.no_grad():\n",
    "            for batch in va_loader:\n",
    "                for b in batch:\n",
    "                    logit = model.forward_single(b[\"t\"].to(device), b[\"dose_t\"].to(device), b[\"dose_a\"].to(device),\n",
    "                                                 float(b[\"bw\"]), float(b[\"cm\"]))\n",
    "                    p = torch.sigmoid(logit).item()\n",
    "                    ys.append(float(b[\"y\"])); ps.append(p)\n",
    "        y = np.array(ys); p = np.array(ps)\n",
    "        metrics = _compute_metrics(y, p, thr=0.5)\n",
    "\n",
    "        if metrics[\"f1\"] > best[0]:\n",
    "            best = (metrics[\"f1\"], {\"epoch\":ep, **metrics})\n",
    "\n",
    "        if ep%10==0 or ep<=3:\n",
    "            print(f\"[ep {ep:03d}] acc={metrics['acc']:.3f} f1={metrics['f1']:.3f} \"\n",
    "                  f\"prec={metrics['prec']:.3f} rec={metrics['rec']:.3f} \"\n",
    "                  f\"roc_auc={metrics['roc_auc']:.3f} pr_auc={metrics['pr_auc']:.3f}\")\n",
    "\n",
    "    print(\"best(valid):\", best[1])\n",
    "    return model, best[1]\n",
    "\n",
    "\n",
    "# -------- 인구 공변량 샘플러 --------\n",
    "def subject_cov_sampler(pd_df: pd.DataFrame, col_BW: Optional[str], col_COMED: Optional[str],\n",
    "                        n:int, scenario:str=\"base\", rng_seed:int=123):\n",
    "    obs_bw = pd.read_csv(CSV)  # ensure same source? but better use pd_df\n",
    "    obs_bw = pd_df[col_BW].dropna().to_numpy(dtype=float) if col_BW is not None else np.full(len(pd_df), 80.0)\n",
    "    obs_cm = pd_df[col_COMED].dropna().to_numpy(dtype=float) if col_COMED is not None else np.zeros(len(pd_df))\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "    if scenario==\"base\":\n",
    "        idx = rng.integers(0, len(obs_bw), size=n)\n",
    "        return obs_bw[idx], obs_cm[idx]\n",
    "    elif scenario==\"bw_wide\":\n",
    "        bw = rng.uniform(70.0, 140.0, size=n)\n",
    "        cm = obs_cm[rng.integers(0, len(obs_cm), size=n)] if len(obs_cm)>0 else np.zeros(n)\n",
    "        return bw, cm\n",
    "    elif scenario==\"no_comed\":\n",
    "        idx = rng.integers(0, len(obs_bw), size=n)\n",
    "        return obs_bw[idx], np.zeros(n)\n",
    "    else:\n",
    "        raise ValueError(\"unknown scenario\")\n",
    "\n",
    "# -------- 정상상태(SS) 평가: MLP --------\n",
    "@torch.no_grad()\n",
    "def success_fraction_for_dose_ss_mlp(model: PDMLPClassifier, dose_mg: float, freq_h: int,\n",
    "                                     last_window_h: int, pd_df, col_BW: Optional[str], col_COMED: Optional[str],\n",
    "                                     Nsubj=300, scenario=\"base\", decision_threshold=0.5,\n",
    "                                     grid_step_h=1.0) -> float:\n",
    "    bw_arr, cm_arr = subject_cov_sampler(pd_df, col_BW, col_COMED, Nsubj, scenario=scenario)\n",
    "    tau = model.tau_from_cov_np(bw_arr, cm_arr, device=next(model.parameters()).device)\n",
    "    tgrid = np.arange(0.0, last_window_h + 1e-6, grid_step_h, dtype=float)\n",
    "    ok = 0\n",
    "    for i in range(Nsubj):\n",
    "        denom = (1.0 - np.exp(-float(freq_h) / max(tau[i],1e-6)))\n",
    "        denom = max(denom, 1e-6)\n",
    "        e_t = dose_mg * np.exp(-tgrid / max(tau[i],1e-6)) / denom\n",
    "        bwc = (bw_arr[i] - model.bw_mean) / 10.0\n",
    "        cm  = cm_arr[i]\n",
    "        X = torch.tensor(np.stack([e_t, np.full_like(e_t, bwc), np.full_like(e_t, cm)], axis=1),\n",
    "                         dtype=torch.float32, device=next(model.parameters()).device)\n",
    "        logits = model.mlp(X).squeeze(1)\n",
    "        probs = torch.sigmoid(logits).detach().cpu().numpy()\n",
    "        if probs.min() >= decision_threshold:\n",
    "            ok += 1\n",
    "    return ok / Nsubj\n",
    "\n",
    "def search_min_dose_ss(model: PDMLPClassifier, grid, freq_h, last_window_h, pd_df,\n",
    "                       col_BW: Optional[str], col_COMED: Optional[str],\n",
    "                       Nsubj=300, scenario=\"base\", target=0.9, decision_threshold=0.5):\n",
    "    rows = []\n",
    "    for d in grid:\n",
    "        frac = success_fraction_for_dose_ss_mlp(model, d, freq_h, last_window_h, pd_df, col_BW, col_COMED,\n",
    "                                                Nsubj=Nsubj, scenario=scenario, decision_threshold=decision_threshold)\n",
    "        rows.append({\"dose\": d, \"fraction\": frac})\n",
    "    df_res = pd.DataFrame(rows).sort_values(\"dose\")\n",
    "    feas = df_res[df_res[\"fraction\"]>=target]\n",
    "    best = feas.iloc[0][\"dose\"] if len(feas)>0 else None\n",
    "    return df_res, best\n",
    "\n",
    "# -------- 학습 실행 (MLP 하이퍼파라미터 적용) --------\n",
    "model, valid_best = train_classifier(train_ds, valid_ds,\n",
    "                                     pd_threshold=PD_THRESHOLD, epochs=EPOCHS, lr=LR,\n",
    "                                     mlp_hidden=MLP_HIDDEN, mlp_layers=MLP_LAYERS, mlp_dropout=MLP_DROPOUT)\n",
    "print(\"\\nValidation best:\", valid_best)\n",
    "\n",
    "# -------- 용량 탐색 (MLP 전용) --------\n",
    "daily_grid  = [0.5*i for i in range(0, 121)]  # 0..60 mg, 0.5 mg 단위\n",
    "weekly_grid = [5*i   for i in range(0, 41)]   # 0..200 mg, 5 mg 단위\n",
    "\n",
    "daily_base,  best_daily_base  = search_min_dose_ss(model, daily_grid,  24, 24,  pdf, col_BW, col_COMED,\n",
    "                                                   Nsubj=N_SUBJ, scenario=\"base\", target=0.90)\n",
    "weekly_base, best_weekly_base = search_min_dose_ss(model, weekly_grid, 168, 168, pdf, col_BW, col_COMED,\n",
    "                                                   Nsubj=N_SUBJ, scenario=\"base\", target=0.90)\n",
    "\n",
    "daily_bw,   best_daily_bw   = search_min_dose_ss(model, daily_grid,  24, 24,  pdf, col_BW, col_COMED,\n",
    "                                                 Nsubj=N_SUBJ, scenario=\"bw_wide\", target=0.90)\n",
    "weekly_bw,  best_weekly_bw  = search_min_dose_ss(model, weekly_grid, 168, 168, pdf, col_BW, col_COMED,\n",
    "                                                 Nsubj=N_SUBJ, scenario=\"bw_wide\", target=0.90)\n",
    "\n",
    "daily_nocm, best_daily_nocm = search_min_dose_ss(model, daily_grid,  24, 24,  pdf, col_BW, col_COMED,\n",
    "                                                 Nsubj=N_SUBJ, scenario=\"no_comed\", target=0.90)\n",
    "weekly_nocm,best_weekly_nocm= search_min_dose_ss(model, weekly_grid, 168, 168, pdf, col_BW, col_COMED,\n",
    "                                                 Nsubj=N_SUBJ, scenario=\"no_comed\", target=0.90)\n",
    "\n",
    "daily_75,   best_daily_75   = search_min_dose_ss(model, daily_grid,  24, 24,  pdf, col_BW, col_COMED,\n",
    "                                                 Nsubj=N_SUBJ, scenario=\"base\", target=0.75)\n",
    "weekly_75,  best_weekly_75  = search_min_dose_ss(model, weekly_grid, 168, 168, pdf, col_BW, col_COMED,\n",
    "                                                 Nsubj=N_SUBJ, scenario=\"base\", target=0.75)\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"scenario\":\"Base (Phase 1-like)\", \"target\":\"90%\", \"once-daily (mg)\": best_daily_base,  \"once-weekly (mg)\": best_weekly_base},\n",
    "    {\"scenario\":\"BW 70–140 kg\",        \"target\":\"90%\", \"once-daily (mg)\": best_daily_bw,    \"once-weekly (mg)\": best_weekly_bw},\n",
    "    {\"scenario\":\"No COMED allowed\",    \"target\":\"90%\", \"once-daily (mg)\": best_daily_nocm,  \"once-weekly (mg)\": best_weekly_nocm},\n",
    "    {\"scenario\":\"Base (Phase 1-like)\", \"target\":\"75%\", \"once-daily (mg)\": best_daily_75,    \"once-weekly (mg)\": best_weekly_75},\n",
    "])\n",
    "print(\"\\n=== Dose recommendations summary ===\")\n",
    "print(summary.to_string(index=False))\n",
    "# -------- test 평가 --------\n",
    "\n",
    "\n",
    "def evaluate_dataset(model, dataset, batch_size=512):\n",
    "    device = next(model.parameters()).device\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=_collate)\n",
    "    ys, ps = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            for b in batch:\n",
    "                logit = model.forward_single(\n",
    "                    b[\"t\"].to(device), b[\"dose_t\"].to(device), b[\"dose_a\"].to(device),\n",
    "                    float(b[\"bw\"]), float(b[\"cm\"])\n",
    "                )\n",
    "                ys.append(float(b[\"y\"]))\n",
    "                ps.append(torch.sigmoid(logit).item())\n",
    "    y = np.array(ys); p = np.array(ps)\n",
    "    return _compute_metrics(y, p, thr=0.5)\n",
    "\n",
    "test_metrics = evaluate_dataset(model, test_ds)\n",
    "print(\"\\n=== Final TEST metrics (unseen IDs) ===\")\n",
    "for k, v in test_metrics.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"{k:>8s}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"{k:>8s}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28cd5286-fd3e-45a8-9248-9905ed3e8168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{14, 15, 16, 17, 18, 19, 20, 24, 26, 27, 28, 29, 30, 31, 32, 36, 38, 39, 40, 41, 42, 43, 44, 48} {35, 37, 13, 47, 23, 25} {33, 34, 45, 46, 21, 22}\n"
     ]
    }
   ],
   "source": [
    "print(ids_tr,ids_va, ids_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99362dd6-3497-4869-a216-9e8e9b6d1f66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{14, 15, 16, 17, 18, 19, 20, 24, 26, 27, 28, 29, 30, 31, 32, 36, 38, 39, 40, 41, 42, 43, 44, 48} {35, 37, 13, 47, 23, 25} {33, 34, 45, 46, 21, 22}\n"
     ]
    }
   ],
   "source": [
    "print(ids_tr,ids_va, ids_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3d53ca0-c13a-4eb8-b21e-9201cfb3767c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected columns: {'ID': 'ID', 'TIME': 'TIME', 'DV': 'DV', 'EVID': 'EVID', 'AMT': 'AMT', 'BW': 'BW', 'COMED': 'COMED'}\n",
      "PD rows: 1200 Dose rows: 756\n",
      "[ID split by fixed dose groups] (70/15/15)\n",
      " train IDs: 24 | valid IDs: 6 | test IDs: 6\n",
      " 1mg -> train/valid/test: 8 2 2\n",
      " 3mg -> train/valid/test: 8 2 2\n",
      "10mg -> train/valid/test: 8 2 2\n",
      "#samples -> train: 600 | valid: 150 | test: 150\n",
      "[ep 001] acc=0.787 f1=0.000 prec=0.000 rec=0.000 roc_auc=0.705 pr_auc=0.387\n",
      "[ep 002] acc=0.787 f1=0.000 prec=0.000 rec=0.000 roc_auc=0.585 pr_auc=0.456\n",
      "[ep 003] acc=0.787 f1=0.000 prec=0.000 rec=0.000 roc_auc=0.599 pr_auc=0.465\n",
      "[ep 010] acc=0.827 f1=0.629 prec=0.579 rec=0.688 roc_auc=0.796 pr_auc=0.562\n",
      "[ep 020] acc=0.880 f1=0.735 prec=0.694 rec=0.781 roc_auc=0.914 pr_auc=0.852\n",
      "[ep 030] acc=0.947 f1=0.867 prec=0.929 rec=0.812 roc_auc=0.976 pr_auc=0.939\n",
      "[ep 040] acc=0.953 f1=0.881 prec=0.963 rec=0.812 roc_auc=0.991 pr_auc=0.972\n",
      "[ep 050] acc=0.953 f1=0.881 prec=0.963 rec=0.812 roc_auc=0.984 pr_auc=0.956\n",
      "[ep 060] acc=0.940 f1=0.852 prec=0.897 rec=0.812 roc_auc=0.984 pr_auc=0.955\n",
      "best(valid): {'epoch': 39, 'acc': 0.9533333333333334, 'prec': 0.9310344827586207, 'rec': 0.84375, 'f1': 0.8852459016393442, 'roc_auc': np.float64(0.9902012711864407), 'pr_auc': np.float64(0.9694234281696172), 'tn': np.int64(116), 'fp': np.int64(2), 'fn': np.int64(5), 'tp': np.int64(27)}\n",
      "\n",
      "Validation best: {'epoch': 39, 'acc': 0.9533333333333334, 'prec': 0.9310344827586207, 'rec': 0.84375, 'f1': 0.8852459016393442, 'roc_auc': np.float64(0.9902012711864407), 'pr_auc': np.float64(0.9694234281696172), 'tn': np.int64(116), 'fp': np.int64(2), 'fn': np.int64(5), 'tp': np.int64(27)}\n",
      "\n",
      "[validation] optimal threshold (by F1): 0.600\n",
      "\n",
      "=== Dose recommendations summary (thr_opt applied) ===\n",
      "           scenario target  once-daily (mg)  once-weekly (mg)\n",
      "Base (Phase 1-like)    90%              7.5              90.0\n",
      "       BW 70–140 kg    90%             16.5               NaN\n",
      "   No COMED allowed    90%              8.0             100.0\n",
      "Base (Phase 1-like)    75%              4.5              40.0\n",
      "\n",
      "=== Final TEST metrics (unseen IDs, thr_opt applied) ===\n",
      "     acc: 0.9200\n",
      "    prec: 0.7778\n",
      "     rec: 0.9459\n",
      "      f1: 0.8537\n",
      " roc_auc: 0.9768\n",
      "  pr_auc: 0.9270\n",
      "      tn: 103\n",
      "      fp: 10\n",
      "      fn: 2\n",
      "      tp: 35\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# PD-only 분류 + 정상상태 용량탐색 (MLP 전용, 지표 확장, 베스트 가중치 복원 + 검증 임계값 적용)\n",
    "# - 데이터: EstData.csv (PD 단위: ng/mL), 임계 3.3 ng/mL\n",
    "# - 모델: MLP (은닉층 개수/히든/드롭아웃 하이퍼파라미터화)\n",
    "# - 분할: 플라시보(0 mg, ID 1–12) 제외, 1/3/10 mg 고정 그룹별 70/15/15 ID 단위 분할\n",
    "# ===========================\n",
    "import os, math, warnings, numpy as np, pandas as pd, random\n",
    "import torch, torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, average_precision_score, confusion_matrix\n",
    ")\n",
    "from typing import Optional\n",
    "from collections import defaultdict\n",
    "from copy import deepcopy\n",
    "\n",
    "# -------- (선택) 난수 고정: 분할/셔플 재현성 --------\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "# -------- 설정 --------\n",
    "CSV = \"EstData.csv\"       # 필요 시 \"/mnt/data/EstData.csv\"\n",
    "PD_THRESHOLD = 3.3\n",
    "EPOCHS = 60\n",
    "LR = 5e-2\n",
    "N_SUBJ = 300\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# MLP 하이퍼파라미터\n",
    "MLP_HIDDEN = 36\n",
    "MLP_LAYERS = 2\n",
    "MLP_DROPOUT = 0.2\n",
    "\n",
    "assert os.path.exists(CSV), f\"CSV not found at {CSV}\"\n",
    "\n",
    "# -------- 유틸: 열 이름 추론 --------\n",
    "def _find_col_like(df, name_opts):\n",
    "    low = {c.lower(): c for c in df.columns}\n",
    "    for n in name_opts:\n",
    "        if n in low: return low[n]\n",
    "    return None\n",
    "\n",
    "# -------- 데이터 로딩/전처리 --------\n",
    "df = pd.read_csv(CSV)\n",
    "\n",
    "col_ID   = _find_col_like(df, [\"id\"])\n",
    "col_TIME = _find_col_like(df, [\"time\"])\n",
    "col_DVID = _find_col_like(df, [\"dvid\"])\n",
    "col_DV   = _find_col_like(df, [\"dv\",\"pd\",\"value\"])\n",
    "col_EVID = _find_col_like(df, [\"evid\"])\n",
    "col_AMT  = _find_col_like(df, [\"amt\",\"dose\",\"dosen\",\"doses\"])\n",
    "col_BW   = _find_col_like(df, [\"bw\",\"weight\",\"bodyweight\"])\n",
    "col_COMED= _find_col_like(df, [\"comed\",\"conmed\",\"concom\"])\n",
    "\n",
    "need = [col_ID, col_TIME, col_DV, col_AMT]\n",
    "miss = [n for n,v in zip([\"ID\",\"TIME\",\"DV\",\"AMT/DOSE\"], need) if v is None]\n",
    "if miss:\n",
    "    warnings.warn(f\"Columns missing (minimum required): {miss}\")\n",
    "\n",
    "# PD 행 추출 (DVID==2가 있으면 그걸 사용)\n",
    "if col_DVID is not None and col_DV is not None:\n",
    "    pdf = df[df[col_DVID]==2].copy()\n",
    "else:\n",
    "    pdf = df.copy()\n",
    "\n",
    "# 투약 이벤트 (EVID==1 우선, 아니면 AMT/DOSE notna)\n",
    "if col_EVID is not None:\n",
    "    dose_df = df[df[col_EVID]==1].copy()\n",
    "else:\n",
    "    dose_df = df[df[col_AMT].notna()].copy()\n",
    "\n",
    "# 숫자 변환\n",
    "for c in [col_TIME, col_DV, col_AMT, col_BW, col_COMED]:\n",
    "    if c is not None:\n",
    "        pdf[c] = pd.to_numeric(pdf[c], errors=\"coerce\")\n",
    "        dose_df[c] = pd.to_numeric(dose_df[c], errors=\"coerce\")\n",
    "\n",
    "# 정렬/필요 열만\n",
    "keep_pd = [c for c in [col_ID,col_TIME,col_DV,col_BW,col_COMED] if c is not None]\n",
    "keep_dose = [c for c in [col_ID,col_TIME,col_AMT] if c is not None]\n",
    "pdf = pdf[keep_pd].dropna().sort_values([col_ID, col_TIME])\n",
    "dose_df = dose_df[keep_dose].dropna().sort_values([col_ID, col_TIME])\n",
    "\n",
    "print(\"Detected columns:\", dict(ID=col_ID, TIME=col_TIME, DV=col_DV, EVID=col_EVID, AMT=col_AMT, BW=col_BW, COMED=col_COMED))\n",
    "print(\"PD rows:\", len(pdf), \"Dose rows:\", len(dose_df))\n",
    "\n",
    "# -------- 데이터셋 --------\n",
    "class PDSamples(Dataset):\n",
    "    def __init__(self, pd_df: pd.DataFrame, dose_df: pd.DataFrame,\n",
    "                 col_ID: str, col_TIME: str, col_DV: str,\n",
    "                 col_BW: Optional[str], col_COMED: Optional[str], pd_threshold: float=3.3):\n",
    "        self.col_ID, self.col_TIME, self.col_DV = col_ID, col_TIME, col_DV\n",
    "        self.col_BW, self.col_COMED = col_BW, col_COMED\n",
    "        self.pd_threshold = pd_threshold\n",
    "\n",
    "        # ID별 투약 히스토리\n",
    "        d_groups = defaultdict(list)\n",
    "        for _, row in dose_df.iterrows():\n",
    "            d_groups[row[col_ID]].append((float(row[col_TIME]), float(row[col_AMT])))\n",
    "        self.dose_map = {k: (np.array([t for t,a in v], dtype=np.float32),\n",
    "                              np.array([a for t,a in v], dtype=np.float32)) for k,v in d_groups.items()}\n",
    "\n",
    "        # 샘플: 각 PD 관측 시점\n",
    "        feats = []\n",
    "        for _, row in pd_df.iterrows():\n",
    "            sid = row[col_ID]\n",
    "            if sid not in self.dose_map:\n",
    "                continue\n",
    "            t = float(row[col_TIME])\n",
    "            val = float(row[col_DV])\n",
    "            y = 1.0 if (val <= pd_threshold) else 0.0\n",
    "            bw = float(row[col_BW]) if col_BW is not None else 70.0\n",
    "            cm = float(row[col_COMED]) if col_COMED is not None else 0.0\n",
    "            feats.append((sid, t, y, bw, cm))\n",
    "        self.samples = feats\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sid, t, y, bw, cm = self.samples[idx]\n",
    "        dose_t, dose_a = self.dose_map.get(sid, (np.zeros(0, dtype=np.float32), np.zeros(0, dtype=np.float32)))\n",
    "        return {\n",
    "            \"t\": torch.tensor(t, dtype=torch.float32),\n",
    "            \"y\": torch.tensor(y, dtype=torch.float32),\n",
    "            \"bw\": torch.tensor(bw, dtype=torch.float32),\n",
    "            \"cm\": torch.tensor(cm, dtype=torch.float32),\n",
    "            \"dose_t\": torch.tensor(dose_t, dtype=torch.float32),\n",
    "            \"dose_a\": torch.tensor(dose_a, dtype=torch.float32),\n",
    "        }\n",
    "\n",
    "def _collate(batch): return batch\n",
    "\n",
    "dataset_all = PDSamples(pdf, dose_df, col_ID, col_TIME, col_DV, col_BW, col_COMED, pd_threshold=PD_THRESHOLD)\n",
    "\n",
    "# -------- ID 단위 분할: 플라시보 제외 + 고정 그룹(1/3/10 mg)별 70/15/15 --------\n",
    "rng = 42\n",
    "placebo_ids = set(range(1, 13))     # 0 mg (제외)\n",
    "ids_1mg     = list(range(13, 25))   # 1 mg\n",
    "ids_3mg     = list(range(25, 37))   # 3 mg\n",
    "ids_10mg    = list(range(37, 49))   # 10 mg\n",
    "\n",
    "ids_in_data = set(df[col_ID].unique())\n",
    "ids_1mg  = sorted(ids_in_data.intersection(ids_1mg))\n",
    "ids_3mg  = sorted(ids_in_data.intersection(ids_3mg))\n",
    "ids_10mg = sorted(ids_in_data.intersection(ids_10mg))\n",
    "\n",
    "def split_70_15_15(ids, seed=42):\n",
    "    if len(ids) == 0:\n",
    "        return [], [], []\n",
    "    tr_ids, temp_ids = train_test_split(ids, test_size=0.30, random_state=seed, shuffle=True)\n",
    "    va_ids, te_ids = train_test_split(temp_ids, test_size=0.50, random_state=seed, shuffle=True)\n",
    "    return list(tr_ids), list(va_ids), list(te_ids)\n",
    "\n",
    "tr_1, va_1, te_1    = split_70_15_15(ids_1mg,  seed=rng)\n",
    "tr_3, va_3, te_3    = split_70_15_15(ids_3mg,  seed=rng)\n",
    "tr_10, va_10, te_10 = split_70_15_15(ids_10mg, seed=rng)\n",
    "\n",
    "ids_tr = set(tr_1 + tr_3 + tr_10)\n",
    "ids_va = set(va_1 + va_3 + va_10)\n",
    "ids_te = set(te_1 + te_3 + te_10)\n",
    "\n",
    "sid_list = [s[0] for s in dataset_all.samples]\n",
    "tr_idx = [i for i, sid in enumerate(sid_list) if sid in ids_tr]\n",
    "va_idx = [i for i, sid in enumerate(sid_list) if sid in ids_va]\n",
    "te_idx = [i for i, sid in enumerate(sid_list) if sid in ids_te]\n",
    "\n",
    "train_ds = Subset(dataset_all, tr_idx)\n",
    "valid_ds = Subset(dataset_all, va_idx)\n",
    "test_ds  = Subset(dataset_all, te_idx)\n",
    "\n",
    "print(\"[ID split by fixed dose groups] (70/15/15)\")\n",
    "print(\" train IDs:\", len(ids_tr), \"| valid IDs:\", len(ids_va), \"| test IDs:\", len(ids_te))\n",
    "print(\" 1mg -> train/valid/test:\", len(tr_1), len(va_1), len(te_1))\n",
    "print(\" 3mg -> train/valid/test:\", len(tr_3), len(va_3), len(te_3))\n",
    "print(\"10mg -> train/valid/test:\", len(tr_10), len(va_10), len(te_10))\n",
    "print(f\"#samples -> train: {len(train_ds)} | valid: {len(valid_ds)} | test: {len(test_ds)}\")\n",
    "\n",
    "# -------- MLP 모델 --------\n",
    "class PDMLPClassifier(nn.Module):\n",
    "    \"\"\"\n",
    "    입력 x=[E(t), (BW-mean)/10, COMED] -> [Linear+ReLU(+Dropout)]*n_layers -> Linear(→1)\n",
    "    노출 계산용 링크: log(tau) = b0 + b1*((BW-mean)/10) + b2*COMED\n",
    "    \"\"\"\n",
    "    def __init__(self, bw_mean: float=70.0, hidden: int=32, n_layers: int=3, dropout_p: float=0.2):\n",
    "        super().__init__()\n",
    "        # tau 링크 파라미터\n",
    "        self.b0 = nn.Parameter(torch.tensor(math.log(24.0)))\n",
    "        self.b1 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.b2 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.bw_mean = float(bw_mean)\n",
    "\n",
    "        layers = []\n",
    "        in_dim = 3\n",
    "        for i in range(n_layers):\n",
    "            layers += [\n",
    "                nn.Linear(in_dim if i==0 else hidden, hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(p=dropout_p) if dropout_p and dropout_p > 0 else nn.Identity(),\n",
    "            ]\n",
    "        layers += [nn.Linear(hidden if n_layers>0 else in_dim, 1)]\n",
    "        self.mlp = nn.Sequential(*layers)\n",
    "\n",
    "    def _tau(self, bw: torch.Tensor, comed: torch.Tensor):\n",
    "        bwc = (bw - self.bw_mean) / 10.0\n",
    "        log_tau = self.b0 + self.b1*bwc + self.b2*comed\n",
    "        return torch.exp(log_tau).clamp_min(1.0)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def tau_from_cov_np(self, bw_np: np.ndarray, cm_np: np.ndarray, device=None):\n",
    "        device = device or next(self.parameters()).device\n",
    "        bw = torch.tensor(bw_np, dtype=torch.float32, device=device)\n",
    "        cm = torch.tensor(cm_np, dtype=torch.float32, device=device)\n",
    "        return self._tau(bw, cm).detach().cpu().numpy()\n",
    "\n",
    "    def forward_single(self, t: torch.Tensor, dose_t: torch.Tensor, dose_a: torch.Tensor,\n",
    "                       bw: float, comed: float):\n",
    "        tau = self._tau(torch.tensor(bw, dtype=torch.float32, device=t.device),\n",
    "                        torch.tensor(comed, dtype=torch.float32, device=t.device))\n",
    "        dt = t - dose_t\n",
    "        mask = (dt >= 0).float()\n",
    "        exposure = (dose_a * torch.exp(-dt.clamp_min(0) / tau) * mask).sum()\n",
    "        x = torch.stack([\n",
    "            exposure,\n",
    "            (torch.tensor(bw, dtype=torch.float32, device=t.device) - self.bw_mean) / 10.0,\n",
    "            torch.tensor(comed, dtype=torch.float32, device=t.device)\n",
    "        ])\n",
    "        return self.mlp(x).squeeze()\n",
    "\n",
    "def _collate(batch): return batch\n",
    "\n",
    "# -------- 지표 계산 --------\n",
    "def _compute_metrics(y_true: np.ndarray, prob: np.ndarray, thr: float = 0.5):\n",
    "    pred = (prob >= thr).astype(int)\n",
    "    acc = accuracy_score(y_true, pred) if len(y_true) else float(\"nan\")\n",
    "    prec = precision_score(y_true, pred, zero_division=0)\n",
    "    rec  = recall_score(y_true, pred, zero_division=0)\n",
    "    f1   = f1_score(y_true, pred, zero_division=0)\n",
    "    try:\n",
    "        roc = roc_auc_score(y_true, prob) if (len(np.unique(y_true))>1) else float(\"nan\")\n",
    "    except Exception:\n",
    "        roc = float(\"nan\")\n",
    "    try:\n",
    "        ap  = average_precision_score(y_true, prob) if (len(np.unique(y_true))>1) else float(\"nan\")\n",
    "    except Exception:\n",
    "        ap  = float(\"nan\")\n",
    "    try:\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true, pred, labels=[0,1]).ravel()\n",
    "    except Exception:\n",
    "        tn=fp=fn=tp = 0\n",
    "    return {\"acc\":acc, \"prec\":prec, \"rec\":rec, \"f1\":f1, \"roc_auc\":roc, \"pr_auc\":ap,\n",
    "            \"tn\":tn, \"fp\":fp, \"fn\":fn, \"tp\":tp}\n",
    "\n",
    "# -------- 학습 루틴 (베스트 가중치 저장/복원 포함) --------\n",
    "def train_classifier(train_ds, valid_ds, epochs=60, lr=5e-2,\n",
    "                     seed=42, mlp_hidden=32, mlp_layers=3, mlp_dropout=0.2):\n",
    "    device = DEVICE\n",
    "    g = torch.Generator().manual_seed(seed)\n",
    "    tr_loader = DataLoader(train_ds, batch_size=128, shuffle=True, collate_fn=_collate, generator=g)\n",
    "    va_loader = DataLoader(valid_ds, batch_size=256, shuffle=False, collate_fn=_collate)\n",
    "\n",
    "    bw_mean = float(np.mean([b[\"bw\"].item() for b in train_ds]))\n",
    "    model = PDMLPClassifier(bw_mean=bw_mean, hidden=mlp_hidden, n_layers=mlp_layers, dropout_p=mlp_dropout).to(device)\n",
    "\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    best = (-1.0, None)\n",
    "    best_state = None\n",
    "\n",
    "    for ep in range(1, epochs+1):\n",
    "        model.train()\n",
    "        for batch in tr_loader:\n",
    "            opt.zero_grad()\n",
    "            loss = 0.0\n",
    "            for b in batch:\n",
    "                logit = model.forward_single(\n",
    "                    b[\"t\"].to(device), b[\"dose_t\"].to(device), b[\"dose_a\"].to(device),\n",
    "                    float(b[\"bw\"]), float(b[\"cm\"])\n",
    "                )\n",
    "                loss = loss + loss_fn(logit.view(()), b[\"y\"].to(device).view(())\n",
    "                )\n",
    "            (loss/len(batch)).backward()\n",
    "            opt.step()\n",
    "\n",
    "        # validation\n",
    "        model.eval(); ys=[]; ps=[]\n",
    "        with torch.no_grad():\n",
    "            for batch in va_loader:\n",
    "                for b in batch:\n",
    "                    logit = model.forward_single(\n",
    "                        b[\"t\"].to(device), b[\"dose_t\"].to(device), b[\"dose_a\"].to(device),\n",
    "                        float(b[\"bw\"]), float(b[\"cm\"])\n",
    "                    )\n",
    "                    ys.append(float(b[\"y\"]))\n",
    "                    ps.append(torch.sigmoid(logit).item())\n",
    "        y = np.array(ys); p = np.array(ps)\n",
    "        metrics = _compute_metrics(y, p, thr=0.5)\n",
    "\n",
    "        # 베스트 스냅샷\n",
    "        if metrics[\"f1\"] > best[0]:\n",
    "            best = (metrics[\"f1\"], {\"epoch\":ep, **metrics})\n",
    "            best_state = deepcopy(model.state_dict())\n",
    "\n",
    "        if ep%10==0 or ep<=3:\n",
    "            print(f\"[ep {ep:03d}] acc={metrics['acc']:.3f} f1={metrics['f1']:.3f} \"\n",
    "                  f\"prec={metrics['prec']:.3f} rec={metrics['rec']:.3f} \"\n",
    "                  f\"roc_auc={metrics['roc_auc']:.3f} pr_auc={metrics['pr_auc']:.3f}\")\n",
    "\n",
    "    # 베스트 가중치 복원\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "\n",
    "    print(\"best(valid):\", best[1])\n",
    "    return model, best[1]\n",
    "\n",
    "# -------- 검증셋 기반 임계값 탐색 --------\n",
    "def predict_dataset(model, dataset, batch_size=512):\n",
    "    device = next(model.parameters()).device\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=_collate)\n",
    "    ys, ps = [], []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            for b in batch:\n",
    "                logit = model.forward_single(\n",
    "                    b[\"t\"].to(device), b[\"dose_t\"].to(device), b[\"dose_a\"].to(device),\n",
    "                    float(b[\"bw\"]), float(b[\"cm\"])\n",
    "                )\n",
    "                ys.append(float(b[\"y\"]))\n",
    "                ps.append(torch.sigmoid(logit).item())\n",
    "    return np.array(ys), np.array(ps)\n",
    "\n",
    "def find_optimal_threshold(y, p, mode=\"f1\"):\n",
    "    thr_grid = np.linspace(0.05, 0.95, 19)\n",
    "    best_thr, best_score = 0.5, -1.0\n",
    "    for thr in thr_grid:\n",
    "        m = _compute_metrics(y, p, thr)\n",
    "        score = m[\"f1\"] if mode == \"f1\" else (m[\"rec\"] + m[\"prec\"] - 1)\n",
    "        if score > best_score:\n",
    "            best_score, best_thr = score, thr\n",
    "    return best_thr\n",
    "\n",
    "# -------- 인구 공변량 샘플러 --------\n",
    "def subject_cov_sampler(pd_df: pd.DataFrame, col_BW: Optional[str], col_COMED: Optional[str],\n",
    "                        n:int, scenario:str=\"base\", rng_seed:int=123):\n",
    "    obs_bw = pd_df[col_BW].dropna().to_numpy(dtype=float) if col_BW is not None else np.full(len(pd_df), 80.0)\n",
    "    obs_cm = pd_df[col_COMED].dropna().to_numpy(dtype=float) if col_COMED is not None else np.zeros(len(pd_df))\n",
    "    rng = np.random.default_rng(rng_seed)\n",
    "    if scenario==\"base\":\n",
    "        idx = rng.integers(0, len(obs_bw), size=n)\n",
    "        return obs_bw[idx], obs_cm[idx]\n",
    "    elif scenario==\"bw_wide\":\n",
    "        # 외삽: 70~140 kg 구간에서 균등 샘플\n",
    "        bw = rng.uniform(70.0, 140.0, size=n)\n",
    "        cm = obs_cm[rng.integers(0, len(obs_cm), size=n)] if len(obs_cm)>0 else np.zeros(n)\n",
    "        return bw, cm\n",
    "    elif scenario==\"no_comed\":\n",
    "        idx = rng.integers(0, len(obs_bw), size=n)\n",
    "        return obs_bw[idx], np.zeros(n)\n",
    "    else:\n",
    "        raise ValueError(\"unknown scenario\")\n",
    "\n",
    "# -------- 정상상태(SS) 평가: MLP --------\n",
    "@torch.no_grad()\n",
    "def success_fraction_for_dose_ss_mlp(\n",
    "    model: PDMLPClassifier, dose_mg: float, freq_h: int, last_window_h: int,\n",
    "    pd_df, col_BW: Optional[str], col_COMED: Optional[str],\n",
    "    Nsubj=300, scenario=\"base\", decision_threshold=0.5,\n",
    "    grid_step_h=1.0, agg=\"min\", alpha=0.9\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    agg:\n",
    "      - \"min\"      : 창 내 모든 시점에서 확률 >= threshold\n",
    "      - \"trough\"   : 마지막 시점(트러프)에서만 확률 >= threshold\n",
    "      - \"mean\"     : 창 내 평균 확률 >= threshold\n",
    "      - \"coverage\" : 창 내 확률 >= threshold인 비율이 alpha 이상\n",
    "    \"\"\"\n",
    "    bw_arr, cm_arr = subject_cov_sampler(pd_df, col_BW, col_COMED, Nsubj, scenario=scenario)\n",
    "    tau = model.tau_from_cov_np(bw_arr, cm_arr, device=next(model.parameters()).device)\n",
    "    tgrid = np.arange(0.0, last_window_h + 1e-6, grid_step_h, dtype=float)\n",
    "    ok = 0\n",
    "    for i in range(Nsubj):\n",
    "        denom = (1.0 - np.exp(-float(freq_h) / max(tau[i],1e-6)))\n",
    "        denom = max(denom, 1e-6)\n",
    "        e_t = dose_mg * np.exp(-tgrid / max(tau[i],1e-6)) / denom\n",
    "        bwc = (bw_arr[i] - model.bw_mean) / 10.0\n",
    "        cm  = cm_arr[i]\n",
    "        X = torch.tensor(\n",
    "            np.stack([e_t, np.full_like(e_t, bwc), np.full_like(e_t, cm)], axis=1),\n",
    "            dtype=torch.float32, device=next(model.parameters()).device\n",
    "        )\n",
    "        probs = torch.sigmoid(model.mlp(X).squeeze(1)).detach().cpu().numpy()\n",
    "\n",
    "        if agg == \"min\":\n",
    "            success = probs.min() >= decision_threshold\n",
    "        elif agg == \"trough\":\n",
    "            success = probs[-1] >= decision_threshold\n",
    "        elif agg == \"mean\":\n",
    "            success = probs.mean() >= decision_threshold\n",
    "        elif agg == \"coverage\":\n",
    "            success = (probs >= decision_threshold).mean() >= alpha\n",
    "        else:\n",
    "            raise ValueError(\"Unknown agg\")\n",
    "\n",
    "        ok += int(success)\n",
    "    return ok / Nsubj\n",
    "\n",
    "def search_min_dose_ss(\n",
    "    model: PDMLPClassifier, grid, freq_h, last_window_h, pd_df,\n",
    "    col_BW: Optional[str], col_COMED: Optional[str],\n",
    "    Nsubj=300, scenario=\"base\", target=0.9, decision_threshold=0.5,\n",
    "    agg=\"min\", alpha=0.9\n",
    "):\n",
    "    rows = []\n",
    "    for d in grid:\n",
    "        frac = success_fraction_for_dose_ss_mlp(\n",
    "            model, d, freq_h, last_window_h, pd_df, col_BW, col_COMED,\n",
    "            Nsubj=Nsubj, scenario=scenario, decision_threshold=decision_threshold,\n",
    "            agg=agg, alpha=alpha\n",
    "        )\n",
    "        rows.append({\"dose\": d, \"fraction\": frac})\n",
    "    df_res = pd.DataFrame(rows).sort_values(\"dose\")\n",
    "    feas = df_res[df_res[\"fraction\"]>=target]\n",
    "    best = feas.iloc[0][\"dose\"] if len(feas)>0 else None\n",
    "    return df_res, best\n",
    "\n",
    "# -------- 학습 실행 (베스트 복원) --------\n",
    "model, valid_best = train_classifier(\n",
    "    train_ds, valid_ds,\n",
    "    epochs=EPOCHS, lr=LR,\n",
    "    mlp_hidden=MLP_HIDDEN, mlp_layers=MLP_LAYERS, mlp_dropout=MLP_DROPOUT,\n",
    "    seed=SEED\n",
    ")\n",
    "print(\"\\nValidation best:\", valid_best)\n",
    "\n",
    "# -------- 검증셋에서 임계값 최적화 후 활용 --------\n",
    "y_va, p_va = predict_dataset(model, valid_ds)\n",
    "thr_opt = find_optimal_threshold(y_va, p_va, mode=\"f1\")\n",
    "print(f\"\\n[validation] optimal threshold (by F1): {thr_opt:.3f}\")\n",
    "\n",
    "# -------- 용량 탐색 (thr_opt 적용, agg 선택 가능) --------\n",
    "daily_grid  = [0.5*i for i in range(0, 121)]  # 0..60 mg, 0.5 mg 단위\n",
    "weekly_grid = [5*i   for i in range(0, 41)]   # 0..200 mg, 5 mg 단위\n",
    "\n",
    "# 예시: 하루1회(24h 창, min), 주1회(168h 창, trough)로 가정\n",
    "daily_base,  best_daily_base  = search_min_dose_ss(\n",
    "    model, daily_grid,  24, 24,  pdf, col_BW, col_COMED,\n",
    "    Nsubj=N_SUBJ, scenario=\"base\", target=0.90, decision_threshold=thr_opt,\n",
    "    agg=\"min\"\n",
    ")\n",
    "weekly_base, best_weekly_base = search_min_dose_ss(\n",
    "    model, weekly_grid, 168, 168, pdf, col_BW, col_COMED,\n",
    "    Nsubj=N_SUBJ, scenario=\"base\", target=0.90, decision_threshold=thr_opt,\n",
    "    agg=\"trough\"\n",
    ")\n",
    "\n",
    "daily_bw,   best_daily_bw   = search_min_dose_ss(\n",
    "    model, daily_grid,  24, 24,  pdf, col_BW, col_COMED,\n",
    "    Nsubj=N_SUBJ, scenario=\"bw_wide\", target=0.90, decision_threshold=thr_opt,\n",
    "    agg=\"min\"\n",
    ")\n",
    "weekly_bw,  best_weekly_bw  = search_min_dose_ss(\n",
    "    model, weekly_grid, 168, 168, pdf, col_BW, col_COMED,\n",
    "    Nsubj=N_SUBJ, scenario=\"bw_wide\", target=0.90, decision_threshold=thr_opt,\n",
    "    agg=\"trough\"\n",
    ")\n",
    "\n",
    "daily_nocm, best_daily_nocm = search_min_dose_ss(\n",
    "    model, daily_grid,  24, 24,  pdf, col_BW, col_COMED,\n",
    "    Nsubj=N_SUBJ, scenario=\"no_comed\", target=0.90, decision_threshold=thr_opt,\n",
    "    agg=\"min\"\n",
    ")\n",
    "weekly_nocm,best_weekly_nocm= search_min_dose_ss(\n",
    "    model, weekly_grid, 168, 168, pdf, col_BW, col_COMED,\n",
    "    Nsubj=N_SUBJ, scenario=\"no_comed\", target=0.90, decision_threshold=thr_opt,\n",
    "    agg=\"trough\"\n",
    ")\n",
    "\n",
    "daily_75,   best_daily_75   = search_min_dose_ss(\n",
    "    model, daily_grid,  24, 24,  pdf, col_BW, col_COMED,\n",
    "    Nsubj=N_SUBJ, scenario=\"base\", target=0.75, decision_threshold=thr_opt,\n",
    "    agg=\"min\"\n",
    ")\n",
    "weekly_75,  best_weekly_75  = search_min_dose_ss(\n",
    "    model, weekly_grid, 168, 168, pdf, col_BW, col_COMED,\n",
    "    Nsubj=N_SUBJ, scenario=\"base\", target=0.75, decision_threshold=thr_opt,\n",
    "    agg=\"trough\"\n",
    ")\n",
    "\n",
    "summary = pd.DataFrame([\n",
    "    {\"scenario\":\"Base (Phase 1-like)\", \"target\":\"90%\", \"once-daily (mg)\": best_daily_base,  \"once-weekly (mg)\": best_weekly_base},\n",
    "    {\"scenario\":\"BW 70–140 kg\",        \"target\":\"90%\", \"once-daily (mg)\": best_daily_bw,    \"once-weekly (mg)\": best_weekly_bw},\n",
    "    {\"scenario\":\"No COMED allowed\",    \"target\":\"90%\", \"once-daily (mg)\": best_daily_nocm,  \"once-weekly (mg)\": best_weekly_nocm},\n",
    "    {\"scenario\":\"Base (Phase 1-like)\", \"target\":\"75%\", \"once-daily (mg)\": best_daily_75,    \"once-weekly (mg)\": best_weekly_75},\n",
    "])\n",
    "print(\"\\n=== Dose recommendations summary (thr_opt applied) ===\")\n",
    "print(summary.to_string(index=False))\n",
    "\n",
    "# -------- TEST 평가 (thr_opt로) --------\n",
    "def evaluate_dataset(model, dataset, thr=0.5, batch_size=512):\n",
    "    y, p = predict_dataset(model, dataset, batch_size=batch_size)\n",
    "    return _compute_metrics(y, p, thr=thr)\n",
    "\n",
    "test_metrics = evaluate_dataset(model, test_ds, thr=thr_opt)\n",
    "print(\"\\n=== Final TEST metrics (unseen IDs, thr_opt applied) ===\")\n",
    "for k, v in test_metrics.items():\n",
    "    if isinstance(v, float):\n",
    "        print(f\"{k:>8s}: {v:.4f}\")\n",
    "    else:\n",
    "        print(f\"{k:>8s}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9e55c9-ce4c-4ace-9dfb-1a12f72ea050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (gold)",
   "language": "python",
   "name": "gold"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
